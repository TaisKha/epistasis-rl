{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36561cfd-32ed-4517-b533-5d24fc9b0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import ptan\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73ca2027-85fe-4e26-b3d2-448c388bec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpistasisEnv(gym.Env):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.SAMPLE_SIZE = 300 #t1 = t2 = SAMPLE_SIZE\n",
    "        self.reset()\n",
    "        \n",
    "    def establish_phen_gen(self, file):\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "            genotype = np.array(data[\"genotype\"])\n",
    "            self.phenotype = np.array(data[\"phenotype\"])\n",
    "            self.genotype = genotype.T\n",
    "            num_phenotypes = max(self.phenotype)+1\n",
    "            self.disease_snps = data[\"disease_snps\"]\n",
    "            self.phen_gen = [[] for _ in range(num_phenotypes)]\n",
    "            for i in range(len(self.genotype)):\n",
    "                self.phen_gen[self.phenotype[i]].append(i)  \n",
    "            return  self.genotype.shape[0], self.genotype.shape[1]    \n",
    "\n",
    "    \n",
    "    def step(self, action):\n",
    "        snp_ids = self._take_action(action)\n",
    "        print(f\"{snp_ids=}\")\n",
    "        reward = self._count_reward(snp_ids) \n",
    "        self.current_step += 1\n",
    "        done = self.current_step == 1\n",
    "        obs = None if done else self._next_observation()\n",
    "        return obs, reward, done, {}\n",
    "    \n",
    "    def _count_reward(self, snp_ids):\n",
    "        \n",
    "        all_existing_seq = defaultdict(lambda: {'control' : 0, 'case' : 0})\n",
    "        \n",
    "        for i, idv in enumerate(self.obs):\n",
    "            snp_to_cmp = tuple(idv[snp_id] for snp_id in snp_ids) #tuple of SNP that \n",
    "            if self.obs_phenotypes[i] == 0:\n",
    "                all_existing_seq[snp_to_cmp]['control'] += 1\n",
    "            else:\n",
    "                all_existing_seq[snp_to_cmp]['case'] += 1\n",
    "\n",
    "        #count reward      \n",
    "        TP = 0 #HR case\n",
    "        FP = 0 #HR control\n",
    "        TN = 0 #LR control\n",
    "        FN = 0 #LR case\n",
    "\n",
    "        for case_control_count in all_existing_seq.values():\n",
    "          # if seq is in LR group\n",
    "            if case_control_count['case'] <= case_control_count['control']: #вопрос <= или <\n",
    "                FN += case_control_count['case']\n",
    "                TN += case_control_count['control']\n",
    "            else:\n",
    "          # if seq is in HR group\n",
    "                TP += case_control_count['case']\n",
    "                FP += case_control_count['control']\n",
    "        R = (FP + TN) / (TP + FN)\n",
    "        delta = FP / (TP+0.001)\n",
    "        gamma = (TP + FP + TN + FN) / (TP+0.001)\n",
    "        CCR = 0.5 * (TP / (TP + FN) + TN / (FP + TN))\n",
    "        U = (R - delta)**2 / ((1 + delta) * (gamma - delta - 1 + 0.001))\n",
    "        koef = 1\n",
    "        if len(snp_ids) > len(self.disease_snps):\n",
    "                print(\"len(snp_ids) > len(self.disease_snps)\")\n",
    "                koef = 1 / len(snp_ids)\n",
    "\n",
    "        return koef*(CCR + U)\n",
    "\n",
    "  \n",
    "    def reset(self):\n",
    "        pops = [\"ASW\", \"CEU\", \"CEU+TSI\", \"CHD\", \"GIH\", \"JPT+CHB\", \"LWK\", \"MEX\", \"MKK\", \"TSI\"]\n",
    "        sim_idx = np.random.randint(2500)\n",
    "        corp_idx = np.random.randint(1, 23)\n",
    "        pop_idx = np.random.choice(pops)\n",
    "        \n",
    "        filename = f\"/home/tskhakharova/epistasis-rl/epigen/sim/{sim_idx}_{corp_idx}_{pop_idx}.json\"\n",
    "        if not os.path.exists(filename):\n",
    "            os.system(f\"cd /home/tskhakharova/epistasis-rl/epigen/ && python3 simulate_data.py --sim-ids {sim_idx} --corpus-id {corp_idx} --pop {pop_idx} --inds 5000 --snps 100 --model models/ext_model.ini\")\n",
    "\n",
    "        self.N_IDV, self.N_SNPS = self.establish_phen_gen(filename)\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.N_SNPS,), dtype=np.uint8)\n",
    "        self.observation_space = spaces.Box(low=0, high=2, shape=\n",
    "                        (2*self.SAMPLE_SIZE, self.N_SNPS), dtype=np.uint8)\n",
    "        self.obs_phenotypes = None\n",
    "        self.obs = None\n",
    "        self.current_step = 0\n",
    "        self.obs = self._next_observation()\n",
    "        return self.obs\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        pass\n",
    "    \n",
    "    def _take_action(self, action):\n",
    "        chosen_snp_ids = []\n",
    "        for i, choice in enumerate(action):\n",
    "            if choice == 1:\n",
    "                chosen_snp_ids.append(i)\n",
    "        return chosen_snp_ids    \n",
    "    \n",
    "    def _next_observation(self):\n",
    "        id_0 = np.random.choice(self.phen_gen[0], self.SAMPLE_SIZE)\n",
    "        id_1 = np.random.choice(self.phen_gen[1], self.SAMPLE_SIZE)\n",
    "        sample_ids = np.array(list(zip(id_0,id_1))).flatten()\n",
    "        self.obs = np.array([self.genotype[idv] for idv in sample_ids])\n",
    "        self.obs_phenotypes = [self.phenotype[idv] for idv in sample_ids]\n",
    "\n",
    "        return self.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2f49efa-1d9d-4f04-ae7b-4e0650380d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpiProbabilityActionSelector(ptan.actions.ActionSelector):\n",
    "    \"\"\"\n",
    "    Converts probabilities of actions into action by sampling them\n",
    "    \"\"\"\n",
    "    def __call__(self, probs):\n",
    "        assert isinstance(probs, np.ndarray)\n",
    "        assert isinstance(probs[0], np.ndarray)\n",
    "        actions = []\n",
    "#         print(\"EpiProbabilityActionSelector - probs shape:\", probs.shape)\n",
    "#         for prob in probs:\n",
    "# #             print(\"prob\", prob.shape)\n",
    "#             num_selected_snps = 0\n",
    "#             for oneprob in prob:\n",
    "#                 if oneprob > 1/len(prob):\n",
    "#                     num_selected_snps += 1\n",
    "        for prob in probs:\n",
    "            num_selected_snps = 2\n",
    "            # num_selected_snps = 0\n",
    "            # amount_of_oneprob_more_than_1_div_n = 0\n",
    "            # while amount_of_oneprob_more_than_1_div_n < 2:\n",
    "            #     amount_of_oneprob_more_than_1_div_n = 0\n",
    "            #     if num_selected_snps > len(prob)/10:\n",
    "            #         num_selected_snps = int(len(prob)/10)\n",
    "            #         break\n",
    "            #     num_selected_snps += 1\n",
    "            #     for oneprob in prob:\n",
    "            #         if oneprob > 1 / num_selected_snps:\n",
    "            #             amount_of_oneprob_more_than_1_div_n += 1\n",
    "            \n",
    "\n",
    "            chosen_snp = np.random.choice(len(prob), size=num_selected_snps, replace=False, p=prob)\n",
    "            action = np.zeros(len(prob))\n",
    "            for snp in chosen_snp:\n",
    "                action[snp] = 1\n",
    "            actions.append(action)\n",
    "        return np.array(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c11bb3-fafa-48fb-9169-a3654e49f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class SnpPGN(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(SnpPGN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        fx = x.float() / 3\n",
    "#         fx = x.float() / 256\n",
    "        conv_out = self.conv(fx).view(fx.size()[0], -1)\n",
    "        return self.fc(conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "452a179a-12d7-4975-a3e9-961392c15dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): SnpPGN(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv1d(600, 32, kernel_size=(8,), stride=(4,))\n",
      "      (1): ReLU()\n",
      "      (2): Conv1d(32, 64, kernel_size=(4,), stride=(2,))\n",
      "      (3): ReLU()\n",
      "      (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=576, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "snp_ids=[39, 77]\n",
      "snp_ids=[16, 76]\n",
      "snp_ids=[28, 95]\n",
      "snp_ids=[69, 70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tskhakharova/.conda/envs/gen_env/lib/python3.9/site-packages/torch/cuda/nccl.py:51: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  if not isinstance(inputs, collections.Container) or isinstance(inputs, torch.Tensor):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snp_ids=[70, 95]\n",
      "snp_ids=[69, 95]\n",
      "snp_ids=[70, 95]\n",
      "snp_ids=[70, 95]\n",
      "done_episodes > 6\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.01\n",
    "EPISODES_TO_TRAIN = 4\n",
    "COUNT = 6\n",
    "WANDB = False\n",
    "AMOUNT_OF_DATA = 550000\n",
    "\n",
    "\n",
    "def calc_qvals(rewards):\n",
    "    res = []\n",
    "    sum_r = 0.0\n",
    "    for r in reversed(rewards):\n",
    "        sum_r *= GAMMA\n",
    "        sum_r += r\n",
    "        res.append(sum_r)\n",
    "    return list(reversed(res))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    SAMPLE_SIZE = 300 #t1 = t2 = SAMPLE_SIZE\n",
    "    env = EpistasisEnv()\n",
    "    if WANDB:\n",
    "        wandb.init(project=\"epistasis\", entity=\"taisikus\", config={\n",
    "          \"learning_rate\": LEARNING_RATE,\n",
    "          \"gamma\": GAMMA,\n",
    "          \"episodes_to_train\": EPISODES_TO_TRAIN,\n",
    "          \"steps_number\" : COUNT,\n",
    "          \"data_amount\": AMOUNT_OF_DATA,\n",
    "        })\n",
    "        \n",
    "    net = SnpPGN(env.observation_space.shape, env.N_SNPS)\n",
    "    net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    print(net)\n",
    "    agent = ptan.agent.PolicyAgent(net, action_selector=EpiProbabilityActionSelector(),preprocessor=ptan.agent.float32_preprocessor,\n",
    "                                   apply_softmax=True, device=device)\n",
    "    exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, gamma=GAMMA)\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    total_rewards = []\n",
    "    step_idx = 0\n",
    "    done_episodes = 0\n",
    "\n",
    "    batch_episodes = 0\n",
    "    batch_states, batch_actions, batch_qvals = [], [], []\n",
    "    cur_rewards = []\n",
    "\n",
    "    for step_idx, exp in enumerate(exp_source):\n",
    "        batch_states.append(exp.state)\n",
    "#         batch_actions.append(int(exp.action))\n",
    "        batch_actions.append(exp.action)\n",
    "        cur_rewards.append(exp.reward)\n",
    "\n",
    "        if exp.last_state is None:\n",
    "            batch_qvals.extend(calc_qvals(cur_rewards))\n",
    "            cur_rewards.clear()\n",
    "            batch_episodes += 1\n",
    "\n",
    "        # handle new rewards\n",
    "        new_rewards = exp_source.pop_total_rewards()\n",
    "        if new_rewards:\n",
    "            done_episodes += 1\n",
    "            reward = new_rewards[0]\n",
    "            total_rewards.append(reward)\n",
    "            mean_rewards = float(np.mean(total_rewards[-100:]))\n",
    "\n",
    "            if WANDB:\n",
    "                wandb.log({\"reward\": reward, \"mean_100\": mean_rewards, \"episodes\": done_episodes})\n",
    "            if mean_rewards > 0.96:\n",
    "                print(\"Solved in %d steps and %d episodes!\" % (step_idx, done_episodes))\n",
    "                break\n",
    "            if done_episodes > COUNT:\n",
    "                print(f\"done_episodes > {COUNT}\")\n",
    "                break\n",
    "\n",
    "        if batch_episodes < EPISODES_TO_TRAIN:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        states_v = torch.FloatTensor(batch_states)\n",
    "        states_v = states_v.to(device)\n",
    "        batch_actions_t = torch.FloatTensor(batch_actions)\n",
    "        batch_actions_t = batch_actions_t.to(device)\n",
    "        batch_qvals_v = torch.FloatTensor(batch_qvals)\n",
    "        batch_qvals_v = batch_qvals_v.to(device)\n",
    "\n",
    "        logits_v = net(states_v)\n",
    "        log_prob_v = F.log_softmax(logits_v, dim=1)\n",
    "        \n",
    "#         print(log_prob_v.shape)\n",
    "#         print(batch_qvals_v.shape)\n",
    "#         print(len(batch_states))\n",
    "#         print(batch_actions_t.shape)\n",
    "#         log_prob_actions_v = batch_qvals_v * log_prob_v[range(len(batch_states)), batch_actions_t]\n",
    "        log_prob_actions_v = batch_qvals_v * torch.diagonal(torch.mm(log_prob_v, torch.transpose(batch_actions_t, 0, 1)))\n",
    "        loss_v = -log_prob_actions_v.mean()\n",
    "\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_episodes = 0\n",
    "        batch_states.clear()\n",
    "        batch_actions.clear()\n",
    "        batch_qvals.clear()\n",
    "    if WANDB:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb1b76f-89e9-4e23-a7b7-bdb812654a1f",
   "metadata": {},
   "source": [
    "# Размерность observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f829b02-25f7-49c8-b7aa-85c863af4973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0, 2, (600, 100), uint8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(600, 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = EpistasisEnv()\n",
    "print(env.observation_space)\n",
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db75e8b8-3fdf-4716-8b16-deb211dd5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "observation, reward, done, _ = env.step(env.action_space.sample())\n",
    "print('Observation : ' + str(observation.shape))\n",
    "print('Reward      : ' + str(reward))\n",
    "print('Done        : ' + str(done))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c9db7-3b24-4063-bcd1-1279b561ea57",
   "metadata": {},
   "source": [
    "# Создали среду EpistasisEnv() и проверка что работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3d2fa99-66a7-4c81-afb2-5525af575193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 1, ..., 2, 0, 0],\n",
       "       [0, 0, 2, ..., 2, 0, 0],\n",
       "       [0, 1, 0, ..., 2, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = EpistasisEnv()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfc0c914-33c6-4eed-a7de-38a8cbf41798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b091aeec-75e1-46f4-8bd9-6b9da7fc52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.random.random(size=100)\n",
    "probs /= probs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01d6fd4c-f9da-472a-a6f2-90f2dd357cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EpiProbabilityActionSelector - probs shape: (1, 100)\n",
      "(1, 100) [[0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      "  1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      "  1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1.\n",
      "  1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.\n",
      "  0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "action_selector = EpiProbabilityActionSelector()\n",
    "probs = np.array([probs])\n",
    "\n",
    "action = action_selector(probs)\n",
    "print(action.shape, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd8cca1e-6903-4300-95fb-30ce0c1a1936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snp_ids=[0, 3, 4, 5, 8, 11, 12, 15, 16, 19, 21, 22, 27, 28, 29, 32, 34, 35, 37, 39, 40, 42, 43, 45, 47, 48, 50, 52, 53, 54, 57, 60, 61, 64, 68, 74, 76, 78, 79, 84, 86, 87, 89, 92, 96, 99]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1, ..., 1, 0, 0],\n",
       "        [0, 0, 2, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, ..., 1, 0, 0],\n",
       "        [0, 0, 2, ..., 1, 0, 0],\n",
       "        [0, 1, 1, ..., 1, 0, 0]]),\n",
       " 1.9990076523764393,\n",
       " True,\n",
       " {})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71393c93-3981-4dbf-bee9-bdbf033d0158",
   "metadata": {},
   "source": [
    "# Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff03396-2953-4201-9266-3b2418763ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "print(env.observation_space)\n",
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94219f-e222-427a-95cb-96fbbb11ebed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abcc8f2-c861-4398-9795-f2a4e66e820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for i in range(500):\n",
    "   observation, reward, done, _ = env.step(env.action_space.sample())\n",
    "   print('Observation : ' + str(observation.shape))\n",
    "   print('Reward      : ' + str(reward))\n",
    "   print('Done        : ' + str(done))\n",
    "   if done:\n",
    "        print(observation)\n",
    "   print('---------------------')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa76c9a7-488e-49af-b046-30c9f5e866af",
   "metadata": {},
   "source": [
    "#  Как я считаю loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12021e98-ed1b-4558-afd7-595939b1472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[0.2,0.3,0.4],[0.5,0.7,0.8],[0.1,0.1,0.1], [0.2,0.2,0.2]], dtype=torch.float64)\n",
    "b = torch.tensor([[0,0,1],[1,0,0],[1,0,1],[0,1,1]], dtype=torch.float64)\n",
    "c = torch.diagonal(torch.mm(a, torch.transpose(b, 0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52034f9d-3ad1-4be6-9713-f02cf35a13b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4000, 0.5000, 0.2000, 0.4000], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7277b81-1ca5-431b-8c8c-16da6a58a736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([4,5,6])\n",
    "c = a*b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a499e40-75d8-48f5-85b3-36126e853f96",
   "metadata": {},
   "source": [
    "# Эксперимент с выбором кол-ва действий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ff52eef-4e98-491a-b94f-db19ba47cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0966, 0.0629, 0.1407, 0.1090, 0.1407, 0.1056, 0.1225, 0.0878, 0.0622,\n",
      "        0.0719])\n",
      "amount_of_oneprob_more_than_1_div_n 0\n",
      "num_selected_snps 1\n",
      "amount_of_oneprob_more_than_1_div_n 0\n",
      "num_selected_snps 2\n",
      "amount_of_oneprob_more_than_1_div_n 0\n",
      "num_selected_snps 3\n",
      "amount_of_oneprob_more_than_1_div_n 0\n",
      "num_selected_snps 4\n",
      "amount_of_oneprob_more_than_1_div_n 0\n",
      "num_selected_snps 5\n",
      "amount_of_oneprob_more_than_1_div_n 0\n",
      "num_selected_snps 6\n",
      "amount_of_oneprob_more_than_1_div_n 0\n",
      "num_selected_snps 7\n",
      "amount_of_oneprob_more_than_1_div_n 2\n",
      "num_selected_snps 8\n"
     ]
    }
   ],
   "source": [
    "prob = torch.softmax(torch.rand(10), 0)\n",
    "print(prob)\n",
    "\n",
    "num_selected_snps = 0\n",
    "amount_of_oneprob_more_than_1_div_n = 0\n",
    "while amount_of_oneprob_more_than_1_div_n <= 1:\n",
    "    if num_selected_snps > len(prob):\n",
    "        break\n",
    "    amount_of_oneprob_more_than_1_div_n = 0\n",
    "    num_selected_snps += 1\n",
    "    for oneprob in prob:\n",
    "        if oneprob > 1 / num_selected_snps:\n",
    "            amount_of_oneprob_more_than_1_div_n += 1\n",
    "    print(\"amount_of_oneprob_more_than_1_div_n\", amount_of_oneprob_more_than_1_div_n )\n",
    "    print(\"num_selected_snps\", num_selected_snps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9f1ab1-6a95-4236-be18-a4d75ed826ec",
   "metadata": {},
   "source": [
    "# Как работает softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "475ed828-23a0-4f3f-bd2d-e0fe9223e119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5205,  0.0326,  0.5631],\n",
      "        [ 1.1893, -1.3357,  0.5580]])\n",
      "tensor([[0.1756, 0.3053, 0.5190],\n",
      "        [0.6204, 0.0497, 0.3300]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "inputs = torch.randn(2, 3)\n",
    "print(inputs)\n",
    "output = F.softmax(inputs, dim=1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552841c-555e-45de-9022-0d899060320b",
   "metadata": {},
   "source": [
    "# Выбираем все числа, которые > 1/n (в данном случае n=3) -- тупой и неработающий подход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809288be-ee77-4198-8f7b-ed2d5441a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = [[0.8, 0.1, 0.1], [0.4, 0.4, 0.2]]\n",
    "for prob in probs:\n",
    "            num_selected_snps = sum(1 for oneprob in prob if oneprob > 1/len(prob))\n",
    "            print(num_selected_snps)\n",
    "            chosen_snp = np.random.choice(len(prob),size=2, p=prob, replace=False)\n",
    "            print(chosen_snp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff13e3e-70b0-46b8-8778-d7ae009f3d48",
   "metadata": {},
   "source": [
    "#  Интересная нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71204046-fbd1-4a04-a02b-0019747ea89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class LinearARD(nn.Module):\n",
    "    def __init__(self, in_features, out_features, threshold, bias=True):\n",
    "        super(LinearARD, self).__init__()\n",
    "        \"\"\"\n",
    "            in_features: int, a number of input features\n",
    "            out_features: int, a number of neurons\n",
    "            threshold: float, a threshold for clipping weights\n",
    "        \"\"\"\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.mu = nn.parameter.Parameter(torch.Tensor(self.out_features, self.in_features)) # torch.nn.parameter.Parameter of size out_features x in_features\n",
    "        self.log_sigma = nn.parameter.Parameter(torch.Tensor(self.out_features, self.in_features)) # torch.nn.parameter.Parameter of size out_features x in_features\n",
    "        self.bias = nn.parameter.Parameter(torch.Tensor(1, self.out_features)) # torch.nn.parameter.Parameter of size 1 x out_features\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.bias.data.zero_()\n",
    "        self.mu.data.normal_(0, 0.02)\n",
    "        self.log_sigma.data.fill_(-5)        \n",
    "        \n",
    "    def forward(self, x):      \n",
    "        # x is a torch.Tensor of shape (number_of_objects, in_features)\n",
    "        # log_alpha is a torch.Tensor of shape (out_features, in_features)\n",
    "        self.log_alpha = 2*self.log_sigma-torch.log(self.mu**2+1e-16)# Compute using self.log_sigma and self.mu\n",
    "        # clipping for a numerical stability\n",
    "        self.log_alpha = torch.clamp(self.log_alpha, -10, 10)   \n",
    "        \n",
    "        if self.training:\n",
    "            # LRT = local reparametrization trick\n",
    "            # lrt_mean is a torch.Tensor of shape (x.shape[0], out_features)\n",
    "            lrt_mean = F.linear(input=x, weight=self.mu, bias=self.bias) # compute mean activation using LRT; you can use F.linear\n",
    "            # lrt_std is a torch.Tensor of shape (x.shape[0], out_features)\n",
    "            lrt_std = torch.sqrt(1e-8+F.linear(input=x**2, weight=torch.exp(2*self.log_sigma), bias=None)) # compute std of activations unsig lrt; you can use F.linear\n",
    "                      # do not forget use torch.sqrt(x + 1e-8) instead of torch.sqrt(x)\n",
    "            # eps is a torch.Tensor of shape (x.shape[0], out_features)\n",
    "            eps = torch.randn_like(lrt_std)# sample of noise for reparametrization\n",
    "            return lrt_mean+lrt_std*eps# sample of activation\n",
    "        \n",
    "        # compute the output of the layer\n",
    "        # use weights W = E q = self.mu\n",
    "        # clip all weight with log_alpha > threshold\n",
    "        return F.linear(input=x, weight=self.mu*(self.log_alpha < self.threshold).float(), bias=self.bias)\n",
    "        \n",
    "    def kl_reg(self):\n",
    "        # kl is a scalar torch.Tensor \n",
    "        # kl = # eval the KL divergence\n",
    "        log_alpha = 2*self.log_sigma-torch.log(self.mu**2+1e-16) # Eval log alpha as a function(log_sigma, W)\n",
    "        log_alpha = torch.clamp(log_alpha, -10, 10)# Clip log alpha to be in [-10, 10] for numerical suability \n",
    "        kl = - 0.5 * torch.log1p(torch.exp(-log_alpha))\n",
    "        KL  = - torch.sum(kl)\n",
    "        return KL\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, threshold):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = LinearARD(100, 300, threshold)\n",
    "        self.fc2 = LinearARD(300,  100, threshold)\n",
    "#         self.fc3 = LinearARD(100,  10, threshold)\n",
    "        self.threshold=threshold\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f61307-181b-4b34-9cf3-2a42eb3b0f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [.conda-gen_env]",
   "language": "python",
   "name": "conda-env-.conda-gen_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
